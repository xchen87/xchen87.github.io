---
title: A Brief History of AI and AI Hardware
date: 2023-05-06 11:35:00 +0800
categories: [AI]
tags: [AI, hardware]
---

Artificial Intelligence may sound like a fancy and cutting-edge term, it has a long and roller-coaster like history.

<div class="timeline">
    <div class="tl-container tl-left">
        <div class="tl-content">
            <h2><a href="#the-dawn">The Dawn (Pre-1960)</a></h2>
            <p>
            1943,M-P Model for Neuron<br>
            1950,Alan Turning: <cite>Computing Machinery and Intelligence</cite><br>
            1956,DSRPAI<br>
            1957,Perceptron
            </p>
        </div>
    </div>
</div>

## The Dawn

The first "artificial intelligence" work was carried out back in 1943 by McCulloch and Pitts. Based on the theoretical neurophysiology and how neurons communicate in the nervous system, [in their paper](https://home.csulb.edu/~cwallis/382/readings/482/mccolloch.logical.calculus.ideas.1943.pdf) they proposed a computational node modelling (M-P Model) that simulates neuron behavior, and proved that any logical proposition can be encoded to a corresponding neuron network by structuring the nodes differently. Given human brain is a neuron network, this hints it encodes a complicated program, and that it can theoretically be simulated through artifical networks so we can achieve an algorithm that can learn and think. Although from today's view their fixed-threshold modeling of neuron was too simple thus flawed, it paved the way for what will be known as Artificial Intelligence, and inspired cross-disciplinary researches between neuroscience and computation.  

Iconic mathematician and computer scientist Alan Turing, also believed that building a learning machine that mimics human brain is possible, but with a different approach. In his famous paper published in 1950 [Computing Machinery and Intelligence](https://academic.oup.com/mind/article/LIX/236/433/986238), Turning discussed his opinions of how to build a *Learning Machine*, and how to evaluate through *Imitation Game* which is now referred to as *Turning Test*.  

In 1956, being proposed by John McCarthy, Marvin Minsky, Claude Shannon, and Nathaniel Rochester, DSRPAI conference took place. It is widely adopted as the "founding event" for AI, during which the term *Artificial Intelligence* was first adopted. It was essentially a brainstorm session on different AI related topics. Though itself did not bring any notable break-through, its profounding impact opened a new chapter for AI.  

In 1957, Frank Rosenblatt proposed the concept of [Perceptron](https://en.wikipedia.org/wiki/Perceptron), a pioneering idea that laid the foundational block for today's deep learning network. In [his work](https://blogs.umass.edu/brain-wars/files/2016/03/rosenblatt-1957.pdf) he proposed the perceptron model with 3 main components: Sensory System, Association System, and Response System. Which is what we see in modern neural net: input layer, weights associative forward propogation, and simple activation function. Through building of the Mark I Perceptron machine a visual pattern classifier was built to demonstrate the idea. The idea quickly gained popularity, but also attracted lots of objection. Especially when after Minsky and Papert published the famous book [Perceptrons: An Introduction to Computational Geometry](https://direct.mit.edu/books/book/3132/PerceptronsAn-Introduction-to-Computational) in 1969, that discussed the limitations of the model, researches in this area significantly dropped which leads to the period called "AI winter".

### Notable Hardwares (Pre-1960)

## The Early Enthusiasm

### Notable Hardwares - (1960-1970)

## Setback

### Notable Hardwares - (1970-1990)

## Reno (1986-Present)

### Notable Hardwares - (1986-Present)
